<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>L // WLM 2023 - 8&nbsp; L8 // Общие линейные модели. Простая и множественная линейная регрессия</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./l9.html" rel="next">
<link href="./l7.html" rel="prev">
<link href="./pics/favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Ничего не найдено",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Очистить",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Отмена",
    "search-submit-button-title": "Отправить",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./pics/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">WLM 2023 // HSE UX LAB</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./../hub/index.html"> 
<span class="menu-text">Хаб</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./../lectures/index.html"> 
<span class="menu-text">Лекции</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./../practice/index.html"> 
<span class="menu-text">Практики</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./../homeworks/index.html"> 
<span class="menu-text">Домашки</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./../projects/index.html"> 
<span class="menu-text">Проекты</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./l8.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">L8 // Общие линейные модели. Простая и множественная линейная регрессия</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Вступление</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">R</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./l1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">L1 // Основы R. Типы и структура данных. Функции и управляющие конструкции</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./l2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">L2 // Предобработка данных. Дата и время Визуализация данных</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Математика и статистика</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./l3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">L3 // Математика для анализа данных</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./l4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">L4 // Теория измерений</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./l5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">L5 // Введение в статистику. Случайный эксперимент и случайные величины</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./l6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">L6 // Оценивание параметров в практике статистического анализа. Тестирование статистических гипотез</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Анализ данных</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./l7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">L7 // Описательные статистики. Корреляционный анализ</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./l8.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">L8 // Общие линейные модели. Простая и множественная линейная регрессия</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./l9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">L9 // Дисперсионный анализ. Ковариационный анализ</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./l10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">L10 // Обобщенные линейные модели. Логистическая регрессия. Пуассоновская регрессия</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./l12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">L12 // Линейные модели со смешанными эффектами</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./l13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">L13 // Кластерный анализ</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./l14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">L14 // Анализ главных компонент и эксплораторный факторный анализ</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./l15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">L15 // Структурное моделирование и конфирматорный факторный анализ</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Источники</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Содержание</h2>
   
  <ul>
  <li><a href="#простая-линейная-регрессия" id="toc-простая-линейная-регрессия" class="nav-link active" data-scroll-target="#простая-линейная-регрессия"><span class="header-section-number">8.1</span> Простая линейная регрессия</a>
  <ul class="collapse">
  <li><a href="#ограничения-корреляционного-анализа" id="toc-ограничения-корреляционного-анализа" class="nav-link" data-scroll-target="#ограничения-корреляционного-анализа"><span class="header-section-number">8.1.1</span> Ограничения корреляционного анализа</a></li>
  <li><a href="#идея-регрессионной-модели" id="toc-идея-регрессионной-модели" class="nav-link" data-scroll-target="#идея-регрессионной-модели"><span class="header-section-number">8.1.2</span> Идея регрессионной модели</a></li>
  <li><a href="#формализация-модели" id="toc-формализация-модели" class="nav-link" data-scroll-target="#формализация-модели"><span class="header-section-number">8.1.3</span> Формализация модели</a></li>
  <li><a href="#идентификация-модели" id="toc-идентификация-модели" class="nav-link" data-scroll-target="#идентификация-модели"><span class="header-section-number">8.1.4</span> Идентификация модели</a></li>
  <li><a href="#тестирование-качества-модели" id="toc-тестирование-качества-модели" class="nav-link" data-scroll-target="#тестирование-качества-модели"><span class="header-section-number">8.1.5</span> Тестирование качества модели</a></li>
  <li><a href="#тестирование-значимости-предикторов" id="toc-тестирование-значимости-предикторов" class="nav-link" data-scroll-target="#тестирование-значимости-предикторов"><span class="header-section-number">8.1.6</span> Тестирование значимости предикторов</a></li>
  <li><a href="#диагностика-модели" id="toc-диагностика-модели" class="nav-link" data-scroll-target="#диагностика-модели"><span class="header-section-number">8.1.7</span> Диагностика модели</a></li>
  <li><a href="#предсказания-на-основе-модели" id="toc-предсказания-на-основе-модели" class="nav-link" data-scroll-target="#предсказания-на-основе-модели"><span class="header-section-number">8.1.8</span> Предсказания на основе модели</a></li>
  </ul></li>
  <li><a href="#множественная-линейная-регрессия" id="toc-множественная-линейная-регрессия" class="nav-link" data-scroll-target="#множественная-линейная-регрессия"><span class="header-section-number">8.2</span> Множественная линейная регрессия</a>
  <ul class="collapse">
  <li><a href="#множественная-линейная-регрессия-с-количественными-предикторами-без-взаимодействия" id="toc-множественная-линейная-регрессия-с-количественными-предикторами-без-взаимодействия" class="nav-link" data-scroll-target="#множественная-линейная-регрессия-с-количественными-предикторами-без-взаимодействия"><span class="header-section-number">8.2.1</span> Множественная линейная регрессия с количественными предикторами без взаимодействия</a></li>
  <li><a href="#проблема-мультиколлинеарности" id="toc-проблема-мультиколлинеарности" class="nav-link" data-scroll-target="#проблема-мультиколлинеарности"><span class="header-section-number">8.2.2</span> Проблема мультиколлинеарности</a></li>
  <li><a href="#множественная-линейная-регрессия-с-количественными-и-категориальными-предикторами-без-взаимодействия" id="toc-множественная-линейная-регрессия-с-количественными-и-категориальными-предикторами-без-взаимодействия" class="nav-link" data-scroll-target="#множественная-линейная-регрессия-с-количественными-и-категориальными-предикторами-без-взаимодействия"><span class="header-section-number">8.2.3</span> Множественная линейная регрессия с количественными и категориальными предикторами без взаимодействия</a></li>
  <li><a href="#множественная-линейная-регрессия-с-количественными-и-категориальными-предикторами-со-взаимодействием" id="toc-множественная-линейная-регрессия-с-количественными-и-категориальными-предикторами-со-взаимодействием" class="nav-link" data-scroll-target="#множественная-линейная-регрессия-с-количественными-и-категориальными-предикторами-со-взаимодействием"><span class="header-section-number">8.2.4</span> Множественная линейная регрессия с количественными и категориальными предикторами со взаимодействием</a></li>
  <li><a href="#множественная-линейная-регрессия-со-взаимодействием-количественных-предикторов" id="toc-множественная-линейная-регрессия-со-взаимодействием-количественных-предикторов" class="nav-link" data-scroll-target="#множественная-линейная-регрессия-со-взаимодействием-количественных-предикторов"><span class="header-section-number">8.2.5</span> Множественная линейная регрессия со взаимодействием количественных предикторов</a></li>
  <li><a href="#сравнение-моделей" id="toc-сравнение-моделей" class="nav-link" data-scroll-target="#сравнение-моделей"><span class="header-section-number">8.2.6</span> Сравнение моделей</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">L8 // Общие линейные модели. Простая и множественная линейная регрессия</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!--- {{< include ../other/_symbols.qmd >}} --->
<!--- Logic --->
<!--- Number sets--->
<!--- Linear Algebra --->
<!--- vectors and matrices --->
<!--- transposed matrix --->
<!--- Probability, Random Vars --->
<!--- Distributions --->
<!--- Other --->
<!--- Trig --->
<!--- Stats --->
<section id="простая-линейная-регрессия" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="простая-линейная-регрессия"><span class="header-section-number">8.1</span> Простая линейная регрессия</h2>
<section id="ограничения-корреляционного-анализа" class="level3" data-number="8.1.1">
<h3 data-number="8.1.1" class="anchored" data-anchor-id="ограничения-корреляционного-анализа"><span class="header-section-number">8.1.1</span> Ограничения корреляционного анализа</h3>
<ul>
<li>Корреляционный анализ <strong>позволяет</strong> изучить линейную взаимосвязь между переменными, оценить её силу и направление, протестировать гипотезу о статистической значимости взаимосвязи.</li>
<li>Корреляционный анализ <strong>не позволяет</strong> предсказывать значения одной переменной на основе значений другой. Изучения связей между несколькими переменными в корреляционном анализе также не очень удобно.</li>
</ul>
<p>Необходимо построение некоторой модели.</p>
</section>
<section id="идея-регрессионной-модели" class="level3" data-number="8.1.2">
<h3 data-number="8.1.2" class="anchored" data-anchor-id="идея-регрессионной-модели"><span class="header-section-number">8.1.2</span> Идея регрессионной модели</h3>
<p>Когда мы строили диаграммы рассеяния, мы добавляли на них <em>линию тренда</em>, которая отражала линейную составляющую связи между визуализируемыми переменными.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Визуально мы такую прямую проведём очень легко, а вот как мы нам получить её математическое выражение?</p>
<p>Первое, что нам нужно вспомнить — это общее уравнение прямой. Оно выглядит так:</p>
<p><span class="math display">\[
y = kx + b,
\]</span></p>
<p>где <span class="math inline">\(k\)</span> — угловой коэффициент (slope), задающий угол наклона прямой к оси <span class="math inline">\(x\)</span>, а <span class="math inline">\(b\)</span> — свободный член (intercept), который обозначает ординату точки пересечения прямой с осью <span class="math inline">\(y\)</span>.</p>
<center>
<figure class="figure">
<img src="pics/line.jpg" class="figure-img">
</figure>
</center>
<p>Таким образом, чтобы получить уравнение прямой, нам надо знать два этих числа.</p>
</section>
<section id="формализация-модели" class="level3" data-number="8.1.3">
<h3 data-number="8.1.3" class="anchored" data-anchor-id="формализация-модели"><span class="header-section-number">8.1.3</span> Формализация модели</h3>
<p>Мы привыкли к тому, что неизвестными являются <span class="math inline">\(x\)</span> и <span class="math inline">\(y\)</span>, но теперь, когда мы ищем уравнение прямой на основе имеющихся наблюдений, ситуация изменяется. Запишем уравнение прямой, используя общепринятые обозначения:</p>
<p><span class="math display">\[
y = b_0 + b_1 x
\]</span></p>
<p>Уравнение отражает зависимость между переменными <span class="math inline">\(x\)</span> и <span class="math inline">\(y\)</span>, значения которых нам известны, так как у нас есть результаты измерений, а вот неизвестными теперь являются <span class="math inline">\(b_0\)</span> и <span class="math inline">\(b_1\)</span>.</p>
<p>В терминах статистической модели:</p>
<ul>
<li>переменная <span class="math inline">\(y\)</span> называется <em>зависимая</em>, <em>предсказываемая</em>, <em>целевая</em> переменная или <em>регрессант</em></li>
<li>переменная <span class="math inline">\(x\)</span> носит названия <em>независимая</em> переменная, <em>предиктор</em> или <em>регрессор</em></li>
<li>числа <span class="math inline">\(b_0\)</span> и <span class="math inline">\(b_1\)</span> называются <em>коэффициентами</em> или <em>параметрами</em> модели</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Зависимые и независимые переменные
</div>
</div>
<div class="callout-body-container callout-body">
<p>Несмотря на использование терминов зависимая и независимая переменные, необходимо чётко понимать, что сам регрессионный анализ, как и корреляционный, ничего нам не говорит о причинности. Мы выражаем <span class="math inline">\(y\)</span> через <span class="math inline">\(x\)</span>, но точно так же можем выразить и <span class="math inline">\(x\)</span> через <span class="math inline">\(y\)</span> — и модель будет подобрана, так как нет никаких математических ограничений. Поэтому если мы хотим сделать по результатам регрессионного анализа вывод о причинно-следственной связи между явлениями, нам необходимо либо серьёзное теоретическое обоснование нашего вывода — почему мы выбрали в качестве зависимой и независимой переменных именно эти? — либо использование экспериментельного дизайна исследования, где мы обосновываем причинно-следственный характер связи именно через дизайн эксперимента.</p>
</div>
</div>
<p>Однако здесь необходимо еще несколько уточнений. Закономерность, которую мы будем моделировать, корректнее записать в следующем виде:</p>
<p><span class="math display">\[
y = \beta_0 + \beta_1x,
\]</span></p>
<p>где <span class="math inline">\(\beta_0\)</span> и <span class="math inline">\(\beta_1\)</span> — параметры генеральной совокупности.</p>
<p>Кроме того, для каждого отдельного объекта генеральной совокупности значение целевой переменной <span class="math inline">\(y_i\)</span> будет также зависеть и он случайных факторов, которые не учитываются параметрами <span class="math inline">\(\beta_0\)</span> и <span class="math inline">\(\beta_1\)</span>, то есть для конкретного объекта генеральной совокупности модель примет вид:</p>
<p><span class="math display">\[
y_i = \beta_0 + \beta_1 x + \varepsilon_i,
\]</span></p>
<p>где <span class="math inline">\(\varepsilon_i\)</span> — случайная изменчивость целевой переменной.</p>
<p>На эту модель мы и будем опираться при оценке параметров <span class="math inline">\(\beta_0\)</span> и <span class="math inline">\(beta_1\)</span>.</p>
</section>
<section id="идентификация-модели" class="level3" data-number="8.1.4">
<h3 data-number="8.1.4" class="anchored" data-anchor-id="идентификация-модели"><span class="header-section-number">8.1.4</span> Идентификация модели</h3>
<p>Модель <span class="math inline">\(y_i = \beta_0 + \beta_1 x + \varepsilon_i\)</span> имеет место в генеральной совокупности, однако, как мы обсуждали много раз ранее, мы всегда работаем с выборкой, поэтому для выборки мы запишем модель в следующем виде:</p>
<p><span class="math display">\[
y_i = b_0 + b_1 x_i + e_i,
\]</span></p>
<p>где <span class="math inline">\(b_0 = \hat \beta_0\)</span> и <span class="math inline">\(b_1 = \hat \beta_1\)</span> — оценка параметров генеральной совокупности, <span class="math inline">\(e_i\)</span> — ошибки (или остатки, residuals) модели.</p>
<p>Идентификация регрессионной модели сводится к нахождению коэффициентов <span class="math inline">\(b_0\)</span> и <span class="math inline">\(b_1\)</span>. Мы хотим провести такую прямую, которая наилучшим образом будет описывать имеющуюся в данных закономерность, поэтому необходимо найти метрику, по которому мы будем определять «хорошесть» нашей прямой.</p>
<p>Графически мы делаем вот что: проводим прямую через облако точек. Очевидно, что красная прямая описывает закономерность совсем плохо, зелёная — чуть получше, а синяя — то, что нам нужно.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Из картинки также видно, что даже синяя прамая не описывает наши данные максимально точно — не все точки попали на прямую. Ясно, что идеальную прямую мы провести и не сможем — точек же целое облако. Поэтому любая построенная нами модель будет содержать ошибку — те самые <span class="math inline">\(e_i\)</span> — вновь по причине вариативности и неопределенности данных.</p>
<p>Уравнение подбираемой нами прямой — синяя на рисунке выше — запишем в следующем виде:</p>
<p><span class="math display">\[
\hat y_i = b_0 + b_1 x_i,
\]</span></p>
<p>где <span class="math inline">\(\hat y_i\)</span> — модельное значение целевой переменной, то есть то, что лежит на построенной нами прямой для конкретного значения регрессора <span class="math inline">\(x_i\)</span>.</p>
<p>Тогда мы сможем отобразить ошибки модели на графике:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Мы заинтересованы в том, чтобы наша модель ошибалась как можно меньше, то есть сумма ошибок <span class="math inline">\(e_i\)</span> была минимальна. Получается, нам надо подобрать такие параметры <span class="math inline">\(b_0\)</span> и <span class="math inline">\(b_1\)</span>, при которых сумма ошибок модели будет наименьшей. Математически это можно записать так:</p>
<p><span class="math display">\[
Q_{\text{res}} = \sum_{i=1}^n e_i^2 \to \min_{b_0, b_1}
\]</span></p>
<p>Обратите внимание, что минимизируется <em>сумма квадратов ошибок</em>, так как отдельные ошибки могут быть как положительными, так и отрицательными — что и отображено на графике выше —- в силу чего сумма ошибок будет равна нулю. Ситуация аналогичная расчету дисперсии, где мы возводили отклонения в квадрат.</p>
<p>Если мы распишем, как определяется ошибка модели, то получится следующее:</p>
<p><span class="math display">\[
Q_{\text{res}} = \sum_{i=1}^n e_i^2 = \sum_{i=1}^n (y_i - \hat y_i)^2 = \sum_{i=1}^n \big( y_i - (b_0 + b_1 x_i) \big)^2
\]</span></p>
<p>Выходит, что <span class="math inline">\(Q_{\text{res}}\)</span> является функцией, зависящей от <span class="math inline">\(b_0\)</span> и <span class="math inline">\(b_1\)</span>, что можно обозначить как <span class="math inline">\(f(b_0, b_1)\)</span>:</p>
<p><span class="math display">\[
Q_{\text{res}} = f(b_0, b_1) = \sum (y_i - \hat y_i)^2 = \sum (y_i - b_0 - b_1x_i)^2 \to \min_{b_0, b_1}
\]</span></p>
<p>В итоге задача идентификации модели линейной регрессии сводится к нахождению минимума функции <span class="math inline">\(Q_{\text{res}} = f(b_0, b_1)\)</span>. Этим занимается метод наименьшиъ квадратов.</p>
<section id="метод-наименьших-квадратов" class="level4" data-number="8.1.4.1">
<h4 data-number="8.1.4.1" class="anchored" data-anchor-id="метод-наименьших-квадратов"><span class="header-section-number">8.1.4.1</span> Метод наименьших квадратов</h4>
<p>Метод наименьших квадратов работает следующим образом. Как уже отмечено выше, условие минимизации ошибки модели представляет собой функцию двух аргументов:</p>
<p><span class="math display">\[
f(b_0, b_1) = \sum (y_i - b_0 - b_1x_i)^2
\]</span></p>
<p>Это квадратичная функция, и чтобы нам дальше удобнее было с ней работать, раскроем скобки:</p>
<p><span class="math display">\[
f(b_0, b_1) = \sum (y_i - b_0 - b_1x_i) (y_i - b_0 - b_1x_i)
\]</span></p>
<p><span class="math display">\[
f(b_0, b_1) =
\sum (y_i^2 - b_0 y_i - b_1 x_i y_i - b_0 y_i - b_1 x_i y_i + b_0 b_1 x_i + b_1^2 x_i^2 + b_0^2 + b_0 b_1 x_i)
\]</span></p>
<p><span class="math display">\[
f(b_0, b_1) =
\sum(y_i^2 - 2 b_1 x_i y_i - 2 y_i b_0 + x_i^2 b_1^2 + b_0^2 + 2 x_i b_1 b_0)
\]</span></p>
<p>Чтобы определить, при каких значения <span class="math inline">\(b_0\)</span> и <span class="math inline">\(b_1\)</span> функция будет принимать минимальное значение, нужно взять две частные производные этой функции по <span class="math inline">\(b_0\)</span> и <span class="math inline">\(b_1\)</span> и приравнять их к нулю.</p>
<p>Берём частные производные:</p>
<p><span class="math display">\[
\frac{f(b_0, b_1)}{\partial b_0} = \sum (-2y_i + 2b_0 + 2x_ib_1) =
-2 \sum \big( y_i - (b_0 + b_1 x_i) \big)
\]</span></p>
<p><span class="math display">\[
\frac{f(b_0, b_1)}{\partial b_1} = \sum (-2 x_i y_i + 2 x_i^2 b_1 + 2 x_i b_0) = -2 \sum \big( y_i - (b_0 + b_1 x_i) \big) x_i
\]</span></p>
<p>Приравниваем производные к нулю и решаем систему уравнений:</p>
<p><span class="math display">\[
\cases {
-2 \sum \big( y_i - (b_0 + b_1 x_i) \big) = 0 \\
-2 \sum \big( y_i - (b_0 + b_1 x_i) \big) x_i = 0
}
\]</span></p>
<p><span class="math display">\[
\cases{
\sum \big( y_i - (b_0 + b_1 x_i) \big) = 0 \\
\sum \big( y_i - (b_0 + b_1 x_i) \big) x_i = 0
}
\]</span></p>
<p><span class="math display">\[
\cases{
\sum y_i - \sum b_0 + \sum b_1 x_i = 0 \\
\sum y_i x_i - \sum b_0 x_i + \sum b_1 x^2_i = 0
}
\]</span></p>
<p><span class="math display">\[
\cases{
\sum b_0 + \sum b_1 x_i = \sum y_i \\
\sum b_0 x_i + \sum b_1 x_i^2 = \sum y_i x_i
}
\]</span></p>
<p><span class="math display">\[
\cases{
b1 \sum x_i + n b_0 = \sum y_i \\
b1 \sum x^2_i + b_0 \sum x_i = \sum y_i x_i
}
\]</span></p>
<p><span class="math display">\[
b_0 = \frac{\sum y_i}{n} - b_1 \frac{\sum x_i}{n} = \bar y - b_1 \bar x
\]</span></p>
<p><span class="math display">\[
b1 \sum x_i^2 + (\bar y - b_1 \bar x) \sum x_i = \sum x_i y_i
\]</span></p>
<p><span class="math display">\[
\underline{b_1 \sum x_i^2} + \bar y \sum x_i - \underline{b_1 \bar x \sum x_i} = \sum x_i y_i
\]</span></p>
<p><span class="math display">\[
b_1 \Big( \sum x_i^2 - \bar x \sum x_i \Big) =
\sum x_i y_i - \bar y \sum x_i
\]</span></p>
<p><span class="math display">\[
b_1 = \frac{\sum x_i y_i - \bar y \sum x_i}{\sum x_i^2 - \bar x \sum x_i} =
\frac{(\sum x_i y_i - \bar y \sum x_i) \times n}{(\sum x_i^2 - \bar x \sum x_i) \times n}
\]</span></p>
<p><span class="math display">\[
b_1 = \frac{\overline{xy} - \bar x \cdot \bar y}{\overline{x^2} - \bar x^2} =
\frac{\overline{xy} - \bar x \bar y}{s_X^2}
\]</span></p>
<p>В сухом остатке из метода наименьших квадратов нам надо вынести две идеи:</p>
<ul>
<li><em>задача идентификации модели линейной регрессии имеет аналитическое решение</em> — то есть мы можем подобрать коэффициенты модели, опираясь только на имеющиеся данные</li>
<li>это аналитическое решение имеет следующий вид:</li>
</ul>
<p><span class="math display">\[
\cases{
b_0 = \bar y - b_1 \bar x \\
b_1 = \frac{\overline{xy} - \bar x \cdot \bar y}{\overline{x^2} - \bar x^2} =
\frac{\overline{xy} - \bar x \bar y}{s_X^2}
}
\]</span></p>
</section>
<section id="матричное-вычисление-коэффициентов" class="level4" data-number="8.1.4.2">
<h4 data-number="8.1.4.2" class="anchored" data-anchor-id="матричное-вычисление-коэффициентов"><span class="header-section-number">8.1.4.2</span> Матричное вычисление коэффициентов</h4>
<p>Частные производные это, конечно, хорошо, однако можно вычислить коэффициенты и проще через матрицы. Имеющуюся у нас модель мы модем записать следующим образом: пусть у нас есть <span class="math inline">\(n\)</span> наблюдений, каждое из которых описывается моделью <span class="math inline">\(y_i = b_0 + b_1 x_i + e_i\)</span>. Тогда мы можем записать следующую систему:</p>
<p><span class="math display">\[
\cases{
b_0 + b_1 x_1 + e_1 = y_1 \\
b_0 + b_1 x_2 + e_2 = y_2 \\
\dots \\
b_0 + b_1 x_n + e_n = y_n \\
}
\]</span></p>
<p>Эту систему мы можем переписать в матричном виде:</p>
<p><span class="math display">\[
\mathbf{X} \mathbf{b} + \mathbf{e} = \mathbf{y},
\]</span></p>
<p>где <span class="math inline">\(\mathbf{y}\)</span> — вектор нашей целевой переменной, <span class="math inline">\(\mathbf{X}\)</span> — матрица предикторов, <span class="math inline">\(\mathbf{b}\)</span> — вектор коэффициентов модели, <span class="math inline">\(\mathbf{e}\)</span> — вектор ошибок (остатков) модели.</p>
<p>Может возникнуть резонный вопрос: «почему <span class="math inline">\(\mathbf{X}\)</span> матрица, ведь у нас только одна независимая переменная?». Так как вектор коэффициентов модели <span class="math inline">\(\mathbf{b}\)</span> содержит два элемента <span class="math inline">\(b_0\)</span> и <span class="math inline">\(b_1\)</span>, то для удобства вычислений к вектору значений предиктора добавляют вектор, состоящий из единиц, который будет отвечать за интерсепт нашей модели — в результате получается матрица <span class="math inline">\(\mathbf{X}\)</span>, которая имеет следующий вид:</p>
<p><span class="math display">\[
\mathbf{X} = \pmatrix{1 &amp; x_1 \\ 1 &amp; x_2 \\ \vdots &amp; \vdots \\ 1 &amp; x_n}
\]</span></p>
<p>Опуская детали, сразу укажем матричное решение для коэффициентов модели:</p>
<p><span class="math display">\[
\mathbf{b} = (\mathbf{X}^\top\mathbf{X})^{-1} \mathbf{X}^\top\mathbf{y}
\]</span></p>
<p>Отметим важную деталь из полученного решения: в ходе вычисления коэффициентов мы берём обратную матрицу от матрицы <span class="math inline">\(\mathbf{X}^\top\mathbf{X}\)</span>. Этот факт нам пригодится в следующем разделе.</p>
</section>
</section>
<section id="тестирование-качества-модели" class="level3" data-number="8.1.5">
<h3 data-number="8.1.5" class="anchored" data-anchor-id="тестирование-качества-модели"><span class="header-section-number">8.1.5</span> Тестирование качества модели</h3>
<p>Окей, коэффициенты модели мы посчитали, а значит и модель теперь подобрана. Хотелось бы понять, насколько она получилась хорошей с точки зрения описания закономерностей данных.</p>
<section id="коэффициент-детерминации" class="level4" data-number="8.1.5.1">
<h4 data-number="8.1.5.1" class="anchored" data-anchor-id="коэффициент-детерминации"><span class="header-section-number">8.1.5.1</span> Коэффициент детерминации</h4>
<p>Первое, что хочется понять — насколько наша модель информативна. Поскольку у нас есть вариативность как одна из основных характеристик данных, подойдем к вопросу через неё. Иначе говоря, нам интересно, сколько дисперсии наших данных модель смогла объяснить. На практике работают не с дисперсией, а с <em>суммой квадратов</em>, что почти то же самое.</p>
<p>Вся изменчивость наших данных называется <strong>общая сумма квадратов (total sum of squares, TSS)</strong> и определяется так:</p>
<p><span class="math display">\[
\text{TSS} = \sum_{i=1}^n (\bar y - y_i)^2
\]</span></p>
<p>Если мы попробуем изобразить это графически, то получим вот что:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Одну часть этой изменчивости объясняет модель — это <strong>объясненная сумма квадратов (explained sum of squares, ESS)</strong>:</p>
<p><span class="math display">\[
\text{ESS} = \sum_{i=1}^n (\bar y - \hat y)^2
\]</span></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Другую часть этой изменчивости модель не улавливает, и она остаётся <strong>необъяснённой (остаточной) (residual sum of squares, RSS)</strong>:</p>
<p><span class="math display">\[
\text{RSS} = \sum_{i=1}^n (y_i - \hat y_i)^2
\]</span></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Если объединить все три извенчивости на одной картинке, то получится следующее:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Явно видно, что</p>
<p><span class="math display">\[
\text{TSS} = \text{ESS} + \text{RSS}
\]</span></p>
<details>
<summary>
Вообще это бы хорошо доказать
</summary>
<p>Так как в расчете сумм квадратов у нас используются, собственно, квадраты, напрямую из визуализации это равенство не следует, однако тем не менее, выполняется.</p>
<p><span class="math display">\[
\begin{split}
\text{TSS} &amp; = \sum (y_i - \bar y)^2 = \\
&amp; =\sum (y_i - \hat y + \hat y - \bar y)^2 = \\
&amp; =\sum \big( (y_i - \hat y_i) + (\hat y_i - \bar y) \big)^2 = \\
&amp; = \sum (y_i - \hat y_i) = \sum (\hat y_i - \bar y) + 2 \sum (y_i - \hat y_i)(\hat y_i - \bar y) = \\
&amp; = \text{RSS} + \text{ESS} + 2 \sum (y_i - \hat y_i)(\hat y_i - \bar y)
\end{split}
\]</span></p>
<p>Окей, осталось доказать, что <span class="math inline">\(2 \sum (y_i - \hat y_i)(\hat y_i - \bar y) = 0\)</span>, и все будет найс.</p>
<p>Так как <span class="math inline">\(b_0 = \bar y - b_1 x\)</span>,</p>
<p><span class="math display">\[
\begin{split}
\sum (y_i - \hat y_i)(\hat y_i - \bar y) &amp; = \sum (y_i - b_0 - b_1 x_i) (b_0 + b_1 x_i - \bar y) = \\
&amp; = \sum (y_i - \bar y + b_1 \bar x - b_1x_i) (\bar y - b_1 \bar x + b_1 x_i - \bar y) = \\
&amp; = \sum \big( (y_i - \bar y) - b_1(x_i - \bar x) \big) \times b_1 (x_i - \bar x) = \\
&amp; = \sum \big( b_1 (x_i - \bar x) (y_i - \bar y) - b_1^2 (x_i - \bar x)^2 \big) = \\
&amp; = b_1 \sum (x_i - \bar x) (y_i - \bar y) - b_1^2 \sum (x_i - \bar x)
\end{split}
\]</span></p>
<p>Так как <span class="math inline">\(b_1 = \frac{\sum(x_i - \bar x)(y_i - \bar y)}{\sum (x_i - \bar x)^2}\)</span>, получается, что:</p>
<p><span class="math display">\[
\begin{split}
\frac{\Big( \sum (x_i - \bar x) (y_i - \bar y) \Big)^2}{\sum (x_i - \bar x)^2} - \frac{\Big( \sum (x_i - \bar x) (y_i - \bar y) \Big)^2 \times \sum (x_i - \bar x)^2}{\Big( \sum (x_i - \bar x)^2\Big)^2} = \\
= \frac{\Big( \sum (x_i - \bar x) (y_i - \bar y) \Big)^2}{\sum (x_i - \bar x)^2} - \frac{\Big( \sum (x_i - \bar x) (y_i - \bar y) \Big)^2}{\sum (x_i - \bar x)^2} = 0
\end{split}
\]</span></p>
</details>
<p>В качестве метрики информативности модели используется доля объясненной дисперсии — эта метрика называется <strong>коэффициент детерминации</strong> <span class="math inline">\(R^2\)</span> и вычисляется по формуле:</p>
<p><span class="math display">\[
R^2 = \frac{\text{ESS}}{\text{TSS}} = 1 - \frac{\text{RSS}}{\text{TSS}}
\]</span></p>
<p>Из формулы следует, что <span class="math inline">\(0 \leq R^2 \leq 1\)</span>. Считается, что если модель объясняется 0.8 и более дисперсии данных, то она хороша, хотя этот порог очень сильно зависит от конкретной задачи и исследовательской области.</p>
<p>Кроме того, отметим, что коэффициент детерминации равен квадрату коэффициента корреляции между целевой переменной и предиктором:</p>
<p><span class="math display">\[
R^2 = r^2
\]</span></p>
</section>
<section id="f-статистика" class="level4" data-number="8.1.5.2">
<h4 data-number="8.1.5.2" class="anchored" data-anchor-id="f-статистика"><span class="header-section-number">8.1.5.2</span> F-статистика</h4>
<p>На основе всё тех же сумм квадратов мы можем сделать вывод о том, насколько наша модель статистически значима. Здесь мы говорим о значимости модели в целом — не о значимости отдельных предикторов, это будет позже. Для этого нам надо заняться тестированием статистической гипотезы. Она формулируется так:</p>
<p><span class="math display">\[
\begin{split}
H_0&amp;: \beta_0 = \beta_1 = 0 \\
H_1&amp;: \beta_0 \neq 0 \vee \beta_1 \neq 0
\end{split}
\]</span></p>
<p>Для тестирования данной гипотезы используется следующая статистика:</p>
<p><span class="math display">\[
F_{\text{df}_e, \text{df}_r} = \frac{\text{MS}_e}{\text{MS}_r} = \frac{\text{ESS}/\text{df}_e}{\text{RSS}/\text{df}_r} \overset{H_0}{\thicksim} F(\text{df}_e, \text{df}_r)
\]</span></p>
<p>Здесь <span class="math inline">\(\text{MS}_e\)</span> — это «средний объясненный квадрат», <span class="math inline">\(\text{MS}_r\)</span> — «средний остаточный квадрат», а <span class="math inline">\(\text{df}_e = p - 1\)</span> и <span class="math inline">\(\text{df}_r = n - p - 1\)</span> — степени свободы для объясненной и остаточной изменчивости, <span class="math inline">\(p\)</span> — количество предикторов в модели, <span class="math inline">\(n\)</span> — число наблюдений. По сути, эта статистика показывает, во сколько раз объясненная дисперсия больше остаточной.</p>
<p>Эта статистика подчиняется F-распределению (распределению Фишера), которое выглядит так (изображен случай <span class="math inline">\(\text{df}_e = 3\)</span>, <span class="math inline">\(\text{df}_e = 50\)</span>):</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Как и всегда, для наблюдаемой <span class="math inline">\(F\)</span>-статистики рассчитывается <em>p-value</em>, на основе значения которого мы делаем вывод о статистической значимости модели в целом.</p>
</section>
<section id="метрики-качества-модели" class="level4" data-number="8.1.5.3">
<h4 data-number="8.1.5.3" class="anchored" data-anchor-id="метрики-качества-модели"><span class="header-section-number">8.1.5.3</span> Метрики качества модели</h4>
<p>Кроме статистического критерия, мы можем использовать и другие показатели качества модели, называемыми метриками качества. В принципе, и коэффициент детерминации является метрикой качества, однако нам часто интересно, насколько ошибается наша модель в своих предсказаниях, поэтому появляются разные способы рассчитать эту ошибку.</p>
<section id="mse" class="level5" data-number="8.1.5.3.1">
<h5 data-number="8.1.5.3.1" class="anchored" data-anchor-id="mse"><span class="header-section-number">8.1.5.3.1</span> MSE</h5>
<p>Первый вариант — вычислить средний квадрат ошибки модели (mean squared error):</p>
<p><span class="math display">\[
\text{MSE} = \frac{1}{n} \sum_{i=1}^n \Big ( y_i - \hat y_i \Big)^2
\]</span></p>
</section>
<section id="rmse" class="level5" data-number="8.1.5.3.2">
<h5 data-number="8.1.5.3.2" class="anchored" data-anchor-id="rmse"><span class="header-section-number">8.1.5.3.2</span> RMSE</h5>
<p>Для сравнения двух моделей это полезная метрика, однако для интерпретации она не очень удобна, так как выражена в квадрате единиц целевой переменной. Однако если извлечь квадратный корень из неё, то она превращается в среднеквадратичную ошибку (root mean squared error) и становится гораздо более интерпретабельной:</p>
<p><span class="math display">\[
\text{RMSE} = \sqrt{\text{MSE}} = \sqrt{\frac{1}{n} \sum_{i=1}^n \Big ( y_i - \hat y_i \Big)^2}
\]</span></p>
</section>
<section id="mae" class="level5" data-number="8.1.5.3.3">
<h5 data-number="8.1.5.3.3" class="anchored" data-anchor-id="mae"><span class="header-section-number">8.1.5.3.3</span> MAE</h5>
<p>Существует и другой способ измерения ошибки модели — если заменить квадрат на модуль, то получим среднюю абсолютную ошибку (mean absolute error):</p>
<p><span class="math display">\[
\text{MAE} = \frac{1}{n} \sum_{i=1}^n |y_i - \hat y_i|
\]</span></p>
</section>
<section id="mape" class="level5" data-number="8.1.5.3.4">
<h5 data-number="8.1.5.3.4" class="anchored" data-anchor-id="mape"><span class="header-section-number">8.1.5.3.4</span> MAPE</h5>
<p>Более того, мы можем оценить точность предсказаний и в относительных значениях — перед суммированием разделим абсолютные отклонения на модуль значения целевой переменной:</p>
<p><span class="math display">\[
\text{MAPE} = \frac{1}{n} \sum_{i=1}^n \Bigg |\frac{y_i - \hat y_i}{y_i} \Bigg|
\]</span></p>
</section>
</section>
</section>
<section id="тестирование-значимости-предикторов" class="level3" data-number="8.1.6">
<h3 data-number="8.1.6" class="anchored" data-anchor-id="тестирование-значимости-предикторов"><span class="header-section-number">8.1.6</span> Тестирование значимости предикторов</h3>
<p>Если модель значима в целом, значит среди её коэффициентов есть те, которые статистически отличны от нуля. Иначе говоря, есть такие предикторы, которые значимо влияют на нашу целевую переменную. В случае простой линейной регрессии предиктора всего два — intercept и slope. Intercept не всегда интерпретабелен, поэтому основное внимание уделают угловому коэффициенту. Формулы для интерсепта будут аналогичны.</p>
<p>Статистические гипотезы для тестирования значимости углового коэффициента будут стандартны:</p>
<p><span class="math display">\[
\begin{split}
H_0&amp;: \beta_1 = 0 \\
H_1&amp;: \beta_1 \neq 0
\end{split}
\]</span></p>
<p>Тестирование гипотез осуществляется с помощью одновыборочного t-теста:</p>
<p><span class="math display">\[
t = \frac{b_1 - \beta_1}{\text{se}_{b_1}} = \frac{b_1}{\text{se}_{b_1}} \overset{H_0}{\thicksim} t(\text{df}_t),
\]</span></p>
<p>где <span class="math inline">\(\text{df}_t = n-p-1\)</span>, <span class="math inline">\(\text{se}_{b_1} = \frac{s_r}{\sum_{i=1}^n (x_i - \bar x)^2}\)</span>, <span class="math inline">\(s_r = \sqrt{\frac{\sum_{i=1}^n (y_i - \hat y_i)^2}{n-2}}\)</span>.</p>
<p>Статистический вывод осуществляется по стандартному алгоритму.</p>
</section>
<section id="диагностика-модели" class="level3" data-number="8.1.7">
<h3 data-number="8.1.7" class="anchored" data-anchor-id="диагностика-модели"><span class="header-section-number">8.1.7</span> Диагностика модели</h3>
<p>Модель линейной регрессии обладает рядом допущений, которые необходимо проверить. При построении модели мы, на самом деле, исходили из нескольких предположений:</p>
<ul>
<li>Во-первых, мы считали, что связь между предикторами и зависимой переменной <strong>линейная</strong>.</li>
<li>Во-вторых, мы предположили, что наша модель полностью улавливает тренд закономерности, а значит <strong>остатки (ошибки) модели случайны</strong>.
<ul>
<li>их <strong>среднее при любых значениях предиктора равно нулю</strong>: <span class="math inline">\(\bar \varepsilon_i = 0\)</span>,</li>
<li>и <strong>они не зависят друг от друга</strong>: <span class="math inline">\(\text{cor}\underset{i \neq j}{(\varepsilon_i, \varepsilon_j)} = 0\)</span></li>
</ul></li>
<li>Кроме того, раз <strong>остатки</strong> заключают в себе случайный компонент модели, то они <strong>должны быть распределены нормально</strong>: <span class="math inline">\(\varepsilon \thicksim \mathcal N(0, \sigma^2_\varepsilon)\)</span>
<ul>
<li>причём их дисперсия должна быть <strong>одинакова при любых значениях предиктора</strong>: <span class="math inline">\(\sigma^2_{\varepsilon_i} = \sigma^2_\varepsilon = \text{const}\)</span></li>
</ul></li>
</ul>
<section id="линейность-связи" class="level4" data-number="8.1.7.1">
<h4 data-number="8.1.7.1" class="anchored" data-anchor-id="линейность-связи"><span class="header-section-number">8.1.7.1</span> Линейность связи</h4>
<p>К сожалению, специального способа проверить это допущение не существует. В случае простой линейной регрессии нас спасает то, что у нас только один предиктор, а значит мы можем изобразить диаграмму рассеяния и визуально проверить, выполняется ли допущение линейности связи.</p>
</section>
<section id="независимость-остатков-друг-от-друга" class="level4" data-number="8.1.7.2">
<h4 data-number="8.1.7.2" class="anchored" data-anchor-id="независимость-остатков-друг-от-друга"><span class="header-section-number">8.1.7.2</span> Независимость остатков друг от друга</h4>
<p>И вновь мы в ситуации, когда у нас нет возможности с помощью статистики проверить данное допущение. Независимость остатков следует из независимости наблюдений, что можно проконтролировать только с помощью дизайна исследования, в том числе дизайна сэмплинга (сбора) выборки.</p>
</section>
<section id="нормальное-распределение-остатков" class="level4" data-number="8.1.7.3">
<h4 data-number="8.1.7.3" class="anchored" data-anchor-id="нормальное-распределение-остатков"><span class="header-section-number">8.1.7.3</span> Нормальное распределение остатков</h4>
<p>А вот это уже проверяемое эмпирически предположение. Здесь существует несколько подходов: можно воспользоваться статистическим тестом (например, тестом Шапиро-Уилка), однако можно обойтись и графической диагностикой. Во-первых, можно построить гистограмму, а во-вторых, есть особы график QQ-plot, который также позволяет проверить допущение о нормальном распределении.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="независимость-остатков-от-предсказанных-значений" class="level4" data-number="8.1.7.4">
<h4 data-number="8.1.7.4" class="anchored" data-anchor-id="независимость-остатков-от-предсказанных-значений"><span class="header-section-number">8.1.7.4</span> Независимость остатков от предсказанных значений</h4>
<p>В случае, если наша модель хорошо схватывает закономерность, представленную в данных, остатки не должны зависеть от предсказанных значений. Это значит два свойства:</p>
<ul>
<li>их <strong>среднее при любых значениях предиктора равно нулю</strong>: <span class="math inline">\(\bar \varepsilon_i = 0\)</span></li>
<li>их дисперсия должна быть <strong>одинакова при любых значениях предиктора</strong>: <span class="math inline">\(\sigma^2_{\varepsilon_i} = \sigma^2_\varepsilon = \text{const}\)</span></li>
</ul>
<p>Допущение о равенстве дисперсии остатков при любых значениях предиктора называется по-умному <strong>гомоскедастичностью</strong>. Её противоположность — это гетероскедастичность. Для проверки этого допущения также существуют статистические тесты, однако оба допущения можно проверить графически на одном и том же графике. Для этого нам необходимо построить диаграмму рассеяния, где по оси x будут идти предсказанные моделью значения, и по оси y остатки модели.</p>
<p>Если мы наблюдаем такую картину, то мы можем заключить, что между остатками модели и предсказанными значениями связи нет:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>На этом графике мы видим, что связь есть — среднее остатков зависит от предсказанного значения. Однако дисперсия остатков при всех значениях целевой переменной, а значит и при всех значениях предиктора, одинакова — гетероскедастичность отсутствует.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>На этом графике мы видим, во-первых, что среднее распределения остатков зависит от предсказанных значений, а во-вторых, распределение остатков гетероскедастично — дисперсия увеличивается с ростом значений целевой переменной.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<section id="влиятельные-наблюдения" class="level5" data-number="8.1.7.4.1">
<h5 data-number="8.1.7.4.1" class="anchored" data-anchor-id="влиятельные-наблюдения"><span class="header-section-number">8.1.7.4.1</span> Влиятельные наблюдения</h5>
<p>Последним аспектом диагностики модели является поиск <strong>влиятельных наблюдений (influential points)</strong>. Это такие точки, которые существенно влияют на положении регрессионной прямой — она сильно меняет свой наклон, если их исключить из выборки. Посмотрим на рисунок:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Здесь красная точка является влиятельным наблюдением, так как сильно меняет кгол наклона регрессионной прямой: черная линия построена только по черным точкам, красная — по всем, включая красную.</p>
<p>Влиятельные наблюдения могут быть статистическими выбросами, но не обязательно. Это могут быть наблюдения, не подчиняющиеся общей закономерности между переменными, то есть наблюдения какой-либо особенной группы, в которых связь между изучаемыми переменными отличается от связи во всей остальной выборке.</p>
<p>Для оценки влиятельных наблюдений вводятся метрики Leverage и Cook’s Distance (расстояние Кука). Мы не будем погружаться в то, как они вычисляются, а лишь скажем, что оценить влиятельность наблюдений можно с помощью графика Residual vs Leverage. Если расстояние Кука для данного наблюдения больше 0.5 (другой порог — больше 1), то это кандидат во влиятельные наблюдения. Необходимо изучить его и выяснить, чем оно может отличаться ото всех других.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="предсказания-на-основе-модели" class="level3" data-number="8.1.8">
<h3 data-number="8.1.8" class="anchored" data-anchor-id="предсказания-на-основе-модели"><span class="header-section-number">8.1.8</span> Предсказания на основе модели</h3>
<p>Поскольку у нас теперь есть математическая модель, мы можем на её основе предсказывать значения целевой переменной для новых значений предиктора. Однако здесь стоит оговорить следующую деталь. Задача предсказания делится на два вида: интерполяция и экстраполяция.</p>
<ul>
<li><strong>Интерполяция</strong> — предсказания значений целевой переменной <strong>внутри</strong> заданного диапазона значений предиктора.</li>
<li><strong>Экстраполяция</strong> — предсказания значений целевой переменной <strong>вне</strong> заданного диапазона значений предиктора.</li>
</ul>
<p>С задачей интерполяции линейные модели справляются хорошо. С задачей экстраполяции — хуже, потому что неизвестно, как себя поведет целевая переменная при тех значениях предиктора, которые нам не попадались. На картинке представлен пример этой мысли. Черные точки — имеющиеся наблюдения. Серые — те, которые мы пытаемся предсказать.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="множественная-линейная-регрессия" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="множественная-линейная-регрессия"><span class="header-section-number">8.2</span> Множественная линейная регрессия</h2>
<p>Простая линейная регрессия хороша, однако позволяет изучать взаимосвязи только между двумя переменными. Собственно, это позволяла делать и корреляция, разве что предсказывать мы не могли. Но пока что профита с введения новой модели немного. Нам же интересно изучать более сложные связи между несколькими переменными — и в этом нам поможет множественная линейная регрессия.</p>
<p>Надо сказать, что вся логика работы с простой линейной регрессией сохраняется и для множественной линейной регрессии — мы так же будем идентифицировать модель методом наименьших квадратов, мы так же будем рассчитывать коэффициент детерминации, тестирования статистическую значимость модели в целом и значимость отдельных предикторов, сравнивать модели друг с другом на основе метрик качества и проводить диагностику модели. Всё — практически — остается таким же. Поэтому далее мы сосредоточимся, прежде всего, на разнообразии моделей множественной линейной регрессии, потому что возможно там много чего.</p>
<section id="множественная-линейная-регрессия-с-количественными-предикторами-без-взаимодействия" class="level3" data-number="8.2.1">
<h3 data-number="8.2.1" class="anchored" data-anchor-id="множественная-линейная-регрессия-с-количественными-предикторами-без-взаимодействия"><span class="header-section-number">8.2.1</span> Множественная линейная регрессия с количественными предикторами без взаимодействия</h3>
<p>Итак, мы хотим изучить связь нескольких предикторов с целевой переменной. Модель в общем-то меняется не сильно — просто добавляется ещё несколько слагаемых:</p>
<p><span class="math display">\[
y_i = b_0 + b_1 x_{i1} + b_2 x_{i2} + \ldots + b_p x_{ip} + e_i
\]</span></p>
<p>Теперь нам необходимо подобрать не два коэффициента, а <span class="math inline">\(p+1\)</span> (<span class="math inline">\(p\)</span> — количество предикторов), но, на самом деле, это ничего не меняет.</p>
<p>Конечно, если мы будем пытаться решить задачу аналитически, то там будут определённые изменения. Однако мы познакомились с матричными вычислениями и можем обратиться к ним. В матричном виде модель будет записываться следующим образом:</p>
<p><span class="math display">\[
\mathbf{X} \mathbf{b} + \mathbf{e} = \mathbf{y}
\]</span></p>
<p>Можно пронаблюдать, что матричная запись идентична случаю простой линейной регрессии. Разница будет в организации матрицы <span class="math inline">\(\mathbf{X}\)</span> и вектора <span class="math inline">\(\mathbf{b}\)</span>:</p>
<p><span class="math display">\[
\mathbf{X} = \pmatrix{
1 &amp; x_{11} &amp; x_{12} &amp; \dots &amp; x_{1p} \\
1 &amp; x_{21} &amp; x_{22} &amp; \dots &amp; x_{2p} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_{n1} &amp; x_{n2} &amp; \dots &amp; x_{np}}
\]</span></p>
<p><span class="math display">\[
\mathbf{b} = \pmatrix{ b_0 &amp; b_1 &amp; b_2 &amp; \dots &amp; b_p}
\]</span></p>
<p>Вычисление же коэффициентов будет осуществляться абсолютно аналогично простой линейной регрессии:</p>
<p><span class="math display">\[
\mathbf{b} = (\mathbf{X}^\top\mathbf{X})^{-1} \mathbf{X}^\top\mathbf{y}
\]</span></p>
<p>Ясно, что не важно, сколько предикторов будет содержать модель — вычисление коэффициентов будет работать одинаково. Однако по сравнению с простой линейной моделью здесь есть одна важная особеность.</p>
</section>
<section id="проблема-мультиколлинеарности" class="level3" data-number="8.2.2">
<h3 data-number="8.2.2" class="anchored" data-anchor-id="проблема-мультиколлинеарности"><span class="header-section-number">8.2.2</span> Проблема мультиколлинеарности</h3>
<p>Предикторы могут быть связаны не только с целевой перемненой, но и друг с другом, что обуславливает <strong>проблему мультиколлинеарности</strong>.</p>
<p>В чем она заключается? Посмотрим ещё раз на формулу, которая нам позволяет вычислить параметры модели:</p>
<p><span class="math display">\[
\mathbf{b} = (\mathbf{X}^\top\mathbf{X})^{-1} \mathbf{X}^\top\mathbf{y}
\]</span></p>
<p>В ходе вычислений мы берем обратную матрицу. Если наши предикторы сильно коррелируют друг с другом (≥ 0.8), то в нашей матрице возникают линейно зависимые столбцы, а значит обратная матрица не будет существовать.</p>
<p>Чем это чревато? В случае абсолютно линейной связи коэффициент модели просто не вычислится — в аутпуте будет <code>NA</code>. Как правило, это намёк на то, чтобы проверить данные — возможно, у вас есть одна и та же переменная, записанная по-разному (например, рост в метрах и сантиметрах). В случае высоких (но меньших единицы) корреляций проблема подбора коэффициентов решается с помощью методов численной оптимизации, однако это может приводить к смещённым оценкам коэффициентов модели, а также большим ошибкам в оценках коэффициентов.</p>
<p>Поэтому с мультиколлинеарностью надо бороться. Вариантов существует много. Наиболее часто используемые: исключение коллинеарных переменных из модели, метод служебной регресии, методы уменьшения размерности (кластерный анализ, PCA и др.).</p>
<section id="коэффициент-вздутия-дисперсии" class="level4" data-number="8.2.2.1">
<h4 data-number="8.2.2.1" class="anchored" data-anchor-id="коэффициент-вздутия-дисперсии"><span class="header-section-number">8.2.2.1</span> Коэффициент вздутия дисперсии</h4>
<p>Для исследования мультиколлинеарности есть два способа. Прежде всего, еще на этапе разведочного анализа, мы можем посмотреть на корреляционную матрицу предикторов — если там есть высокие корреляции, то вполне разумно ожидать проблему мультиколлинеарности. Когда модель уже построена, проверкой на мультиколлинеарность будет расчет <strong>коэффициента вздутия дисперсии (variance inflation factor, VIF)</strong>.</p>
<p>Чтобы его вычислить, проводятся следующие операции:</p>
<ul>
<li>пусть у нас есть модель</li>
</ul>
<p><span class="math display">\[
y = b_0 + b_1 x_1 + b_2 x_2 + \ldots + b_p x_p + e
\]</span></p>
<ul>
<li>построим линейную регрессию, в которой один из предикторов будет регрессироваться по всем другим. Например, для первого предиктора:</li>
</ul>
<p><span class="math display">\[
x_1 = \alpha_0 + \alpha_2 x_2 + \ldots + \alpha_m x_m + e
\]</span></p>
<ul>
<li>вычислим коэффициент детерминации данной модели <span class="math inline">\(R^2_j\)</span></li>
<li>для коэффициента <span class="math inline">\(b_j\)</span> VIF будет определяться так:</li>
</ul>
<p><span class="math display">\[
\text{VIF}_j = \frac{1}{1 - R^2_j}
\]</span></p>
<p>Пороговым значением для вынесение вердикта о наличии мультиколлинеарности считается 3 (иногда 2). Мы этот вердикт всё же вынесем, и будем с мультиколлинеарностью бороться.</p>
</section>
</section>
<section id="множественная-линейная-регрессия-с-количественными-и-категориальными-предикторами-без-взаимодействия" class="level3" data-number="8.2.3">
<h3 data-number="8.2.3" class="anchored" data-anchor-id="множественная-линейная-регрессия-с-количественными-и-категориальными-предикторами-без-взаимодействия"><span class="header-section-number">8.2.3</span> Множественная линейная регрессия с количественными и категориальными предикторами без взаимодействия</h3>
<p>Когда мы имеем дело с количественными предикторами, то всё более-менее ясно — есть зависимость между двумя количественными переменными, описываемая прямой. А что делать, если среди предикторов появляются категориальные переменные?</p>
<p>Рассмотрим картинку:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>У нас есть целевая переменная <code>y</code> и количественный предиктор <code>x</code>, как и раньше. Однако мы видим, что теперь есть и категориальная переменная <code>Group</code>, которая разбивает наши наблюдения на две группы. Кроме того, чисто визуально мы наблюдаем, что обе группы подчиняются одной и той же закономерности, только зеленые точки лежат несколько выше красных. С точки зрения модели мы получаем ситуацию, когда в группах один и тот же наклон регрессионной прямой, но разные интерсепты. В модели это будет фиксироваться так:</p>
<p><span class="math display">\[
y_i = b_0 + b_1 I_{i1} + b_2 x_{i2} + e_i
\]</span></p>
<p>Видим, что в модели появляется некий предиктор <span class="math inline">\(I\)</span>. В принципе, вместо <span class="math inline">\(I_{i1}\)</span> можно написать и <span class="math inline">\(x_{i1}\)</span>, однако мы выделим этот предиктор, так как он категориальный с помощью такой записи.</p>
<p>Переменная <span class="math inline">\(I\)</span> — это индикаторная переменная, которая обладает следующим свойством:</p>
<ul>
<li><span class="math inline">\(I_{i1} = 0\)</span>, если наблюдение под номером <span class="math inline">\(i\)</span> принадлежит к группе <code>Group 1</code>,</li>
<li><span class="math inline">\(I_{i1} = 1\)</span>, если наблюдение под номером <span class="math inline">\(i\)</span> принадлежит к группе <code>Group 2</code>.</li>
</ul>
<p>Таким образом, у нас получается как бы две модели в одной:</p>
<ul>
<li>для наблюдений из <code>Group 1</code> (<span class="math inline">\(I_{i1} = 0\)</span>) модель принимает вид: <span class="math inline">\(\hat y_i = b_0 + b_2 x_{i2}\)</span></li>
<li>для наблюдений из <code>Group 2</code> (<span class="math inline">\(I_{i1} = 1\)</span>) — вид: <span class="math inline">\(\hat y_i = (b_0 + b_1) + b_2 x_{i2}\)</span></li>
</ul>
<p>Коэффициент <span class="math inline">\(b_0\)</span> называется <em>базовым</em> и показывает интесепт регрессионной прямой для одной из групп наблюдений. Коэффициент <span class="math inline">\(b_1\)</span> называется <em>поправочным</em> и показывает разницу в интерсетах регрессионных прямых для двух групп наблюдений.</p>
<p>Визуально представить эту ситуацию можно так:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Оценка и диагностика модели производится аналогично тому, как мы это делали на предыдущих моделях.</p>
</section>
<section id="множественная-линейная-регрессия-с-количественными-и-категориальными-предикторами-со-взаимодействием" class="level3" data-number="8.2.4">
<h3 data-number="8.2.4" class="anchored" data-anchor-id="множественная-линейная-регрессия-с-количественными-и-категориальными-предикторами-со-взаимодействием"><span class="header-section-number">8.2.4</span> Множественная линейная регрессия с количественными и категориальными предикторами со взаимодействием</h3>
<p>Но ведь могут быть различия не только в интерспетах, но и в угловых коэффициентах регрессионных прямых в разных группах наблюдений. Например, такая ситуация:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Для того, чтобы учесть разную степень их связи предиктора с целевой переменной в разных группах наблюдений, нужно ввести <strong>взаимодействие предикторов в модель</strong>.</p>
<p>В данном случае математическая модель будет выглядеть так:</p>
<p><span class="math display">\[
y_i = b_0 + b_1 I_{i1} + b_2 x_{i2} + b_3 I_{i1} x_2
\]</span></p>
<p>Переменная <span class="math inline">\(I\)</span> вновь выступает в качестве индикатора:</p>
<ul>
<li><span class="math inline">\(I_{i1} = 0\)</span>, если наблюдение под номером <span class="math inline">\(i\)</span> принадлежит к группе <code>Group 1</code>,</li>
<li><span class="math inline">\(I_{i1} = 1\)</span>, если наблюдение под номером <span class="math inline">\(i\)</span> принадлежит к группе <code>Group 2</code>.</li>
</ul>
<p>Таким образом, у нас опять получается как бы две модели в одной, однако вторая модель теперь выглядит несколько иначе:</p>
<ul>
<li>для наблюдений из <code>Group 1</code> (<span class="math inline">\(I_{i1} = 0\)</span>) модель принимает вид: <span class="math inline">\(\hat y_i = b_0 + b_2 x_{i2}\)</span></li>
<li>для наблюдений из <code>Group 2</code> (<span class="math inline">\(I_{i1} = 1\)</span>) — вид: <span class="math inline">\(\hat y_i = (b_0 + b_1) + (b_2 + b_3) x_{i2}\)</span></li>
</ul>
<p>Коэффициенты <span class="math inline">\(b_0\)</span> и <span class="math inline">\(b_1\)</span> называются <em>базовыми</em> и показывают интесепт и угловой коэффициент регрессионной прямой для одной из групп наблюдений. Коэффициенты <span class="math inline">\(b_2\)</span> и <span class="math inline">\(b_3\)</span> называются <em>поправочными</em> и показывают разницу в интерсетах и угловых коэффициентах регрессионных прямых для двух групп наблюдений.</p>
<p>Визуально представить эту ситуацию можно так (<span class="math inline">\(\alpha_{\text{Gr}_1}\)</span> и <span class="math inline">\(\alpha_{\text{Gr}_2}\)</span> — углы наклона регрессионных прямых для <code>Group 1</code> и <code>Group 2</code> соответственно):</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="l8_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="множественная-линейная-регрессия-со-взаимодействием-количественных-предикторов" class="level3" data-number="8.2.5">
<h3 data-number="8.2.5" class="anchored" data-anchor-id="множественная-линейная-регрессия-со-взаимодействием-количественных-предикторов"><span class="header-section-number">8.2.5</span> Множественная линейная регрессия со взаимодействием количественных предикторов</h3>
<p>Окей, со взаимодействием категориальных и количественных предикторов все более-менее понятно. По крайней мере, это легко представимо графически. Возникает вопрос: возможно ли учесть в модели взаимодействие двух количественных предикторов? Да, это возможно. Модель от этого даже не слишком усложнится. Возьмем простейший случай, когда у нас два количественных предиктора. Тогда модель, включающая их взаимодействие, будет выглядеть так:</p>
<p><span class="math display">\[
y_i = b_0 + b_1 x_{i1} + b_2 x_{i2} + b_3 x_{i1}x_{i2} + e_i
\]</span></p>
<p>Как можно наблюдать, взаимодействие — это, по сути, ещё один «предиктор», получающийся из перемножения двух исходных. Это достотачно сложно изобразить графически, и часто еще сложнее интерпретировать. Чтобы попытаться приблизиться к интерпретации, попробуем занулить сначала один предиктор, а затем второй, и посмотрим, что получается:</p>
<ul>
<li>если <span class="math inline">\(x_1 = 0\)</span>, то модель приобретает следующий вид: <span class="math inline">\(\hat y_i = b_0 + b_2 x_{i2}\)</span>,</li>
<li>если <span class="math inline">\(x_2 = 0\)</span>, то такой вид: <span class="math inline">\(\hat y_i = b_0 + b_1 x_{i1}\)</span>.</li>
</ul>
<p>То есть <span class="math inline">\(b_1\)</span> и <span class="math inline">\(b_2\)</span> показывают, соответственно, связи целевой переменной с предиктором, когда другой равен нулю — так называемые «условные» связи. Сам же коэффициент <span class="math inline">\(b_3\)</span> при взаимодействии будет показывать сонаправленность связи предикторов с целевой переменной: если связи сонаправленны, то коэффициент положительный, если разнонаправленны — отрицательный. Его статистическая значимость будет говорить о том, «зависит» ли «влияние» одного предиктора от значений другого.</p>
</section>
<section id="сравнение-моделей" class="level3" data-number="8.2.6">
<h3 data-number="8.2.6" class="anchored" data-anchor-id="сравнение-моделей"><span class="header-section-number">8.2.6</span> Сравнение моделей</h3>
<p>Когда у нас есть несколько моделей с разным количеством предикторов, у нас возникает задача сравнить эти модели, чтобы выбрать наиболее простую и интерпретируемую модель, с которой нам дальше будет легче работать. Ведь вполне может случится такое, что мы добавили новый предиктор или несколько, а модель стала не сильно лучше. Здесь нам помогут два показателя.</p>
<section id="скорректированный-коэффициент-детерминации" class="level4" data-number="8.2.6.1">
<h4 data-number="8.2.6.1" class="anchored" data-anchor-id="скорректированный-коэффициент-детерминации"><span class="header-section-number">8.2.6.1</span> Скорректированный коэффициент детерминации</h4>
<p>Мы уже говорили о коэффициенте детерминации, и, конечно же для множественной линейной регрессии он тоже рассчитывается. Однако есть хитрость: если несколько предикторов хотя бы как-то связаны с целевой переменной, при их включении в модель коэффициент детерминации неизбежно будет расти. По этой причине используется <strong>скорректированный коэффициент детерминации (adjusted R-squared)</strong>. Коррестируется он на количество предикторов следующим образом:</p>
<p><span class="math display">\[
R^2_{\text{adj}} = 1 - (1 - R^2) \frac{n-1}{n-p}
\]</span></p>
<p>Скорректированный коэффициент детерминации позволяет сравнивать модели с разным количеством предикторов друг с другом.</p>
</section>
<section id="частный-f-критерий" class="level4" data-number="8.2.6.2">
<h4 data-number="8.2.6.2" class="anchored" data-anchor-id="частный-f-критерий"><span class="header-section-number">8.2.6.2</span> Частный F-критерий</h4>
<p>Для сравнения двух моделей существует и статистический тест, называемый <strong>частным F-критерием</strong>. Пусть у нас есть две модели — (1) полная (full), в которую включены несколько предикторов, и (2) сокращенная (reduced), из которой по сравнению с полной исключены некоторые предикторы:</p>
<p><span class="math display">\[
\begin{split}
(1) &amp;: y_i = b_0 + b_1 x_1 + b_2 x_2 + b_3 x_3 + b_4 x_4 + e \\
(2) &amp;: y_i = b_0 + b_1 x_1 + b_2 x_2 + e
\end{split}
\]</span></p>
<p>Чтобы выяснить, различаются ли статистически данные модели, испольуется следующая статистика:</p>
<p><span class="math display">\[
\begin{split}
H_0 &amp;: \beta_3 = \beta_4 = 0 \\
H_1 &amp;: \beta_3 \neq 0 \vee \beta_4 \neq 0
\end{split}
\]</span></p>
<p><span class="math display">\[
F = \frac{(\text{RSS}_\text{reduced} - \text{RSS}_\text{full})/k}{\text{RSS}_\text{full} / (n-p)},
\]</span></p>
<p><span class="math inline">\(\text{RSS}_\text{reduced}\)</span> — остаточная сумма квадратов сокращенной модели, <span class="math inline">\(\text{RSS}_\text{full}\)</span> — остаточная сумма квадратов полной модели, <span class="math inline">\(n\)</span> — количество наблюдений, <span class="math inline">\(p\)</span> — количество предикторов полной модели, <span class="math inline">\(k\)</span> — количество предикторов, исключенных из полной модели.</p>
<p>Статистический вывод осуществляется по стандартному алгоритму.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Скопировано!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Скопировано!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./l7.html" class="pagination-link" aria-label="L7 // Описательные статистики. Корреляционный анализ">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">L7 // Описательные статистики. Корреляционный анализ</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./l9.html" class="pagination-link" aria-label="L9 // Дисперсионный анализ. Ковариационный анализ">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">L9 // Дисперсионный анализ. Ковариационный анализ</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>